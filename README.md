<div align="center">

# Chess CV

<p align="center">
  <a href="https://github.com/S1M0N38/chess-cv/releases">
    <img alt="GitHub release" src="https://img.shields.io/github/v/release/S1M0N38/chess-cv?include_prereleases&sort=semver&style=for-the-badge&logo=github"/>
  </a>
  <a href="https://pypi.org/project/chess-cv/">
    <img alt="PyPI" src="https://img.shields.io/pypi/v/chess-cv?style=for-the-badge&logo=pypi&logoColor=white"/>
  </a>
  <a href="https://www.python.org/downloads/">
    <img alt="Python 3.13+" src="https://img.shields.io/badge/python-3.13+-blue.svg?style=for-the-badge&logo=python&logoColor=white"/>
  </a>
  <a href="https://opensource.org/licenses/MIT">
    <img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge"/>
  </a>
  <a href="https://s1m0n38.github.io/chess-cv/llms-full.txt">
    <img alt="llms.txt" src="https://img.shields.io/badge/llms.txt-grey?style=for-the-badge"/>
  </a>
</p>

<img src="docs/assets/model.svg" alt="Model Architecture" width="600">

*CNN-based chess piece classifier*

</div>

---

A machine learning project that trains a lightweight CNN (156k parameters) from scratch to classify chess pieces from 32√ó32 pixel square images. The model achieves ~99.84% accuracy on synthetic training data generated by combining 55 board styles (256√ó256px) with 64 piece sets (32√ó32px) from chess.com and lichess.

By rendering pieces onto different board backgrounds and extracting individual squares, the model learns robust piece recognition across various visual styles.

<div align="center">

| Dataset                                                                                         | Accuracy | F1-Score (Macro) |
| ----------------------------------------------------------------------------------------------- | :------: | :--------------: |
| Test Data                                                                                       |  99.84%  |      99.86%      |
| [S1M0N38/chess-cv-openboard](https://huggingface.co/datasets/S1M0N38/chess-cv-openboard) \*     |    -     |      97.25%      |
| [S1M0N38/chess-cv-chessvision](https://huggingface.co/datasets/S1M0N38/chess-cv-chessvision) \* |    -     |      83.83%      |

</div>

- *Dataset with unbalanced class distribution (e.g. many more samples for empty square class), so accuracy is not representative.*

## ‚ö°Ô∏è Quick Start

```bash
pip install chess-cv
```

Then use pre-trained models:

```python
from chess_cv.model import SimpleCNN
from huggingface_hub import hf_hub_download

# Load pre-trained model
model_path = hf_hub_download(repo_id="S1M0N38/chess-cv", filename="pieces.safetensors")
model = SimpleCNN(num_classes=13)
model.load_weights(model_path)

# Make predictions
predictions = model(image_tensor)
```

## ‚ú® Features

**ü™∂ Lightweight Architecture**

- 156k parameter CNN optimized for 32√ó32px images
- 13-class classification (6 white pieces, 6 black pieces, 1 empty)
- MLX framework for efficient training
- Aggressive data augmentation for robust generalization

**üèóÔ∏è Complete Pipeline**

- Synthetic data generation from board/piece combinations
- Training with early stopping and checkpointing
- Comprehensive evaluation with confusion matrices
- Optional Weights & Biases integration for experiment tracking
- Hugging Face Hub deployment for model sharing

## üéØ Models

This project includes two specialized models for chess board analysis:

### Pieces Model (`pieces.safetensors`)

Classifies chess square images into **13 classes**: 6 white pieces (wP, wN, wB, wR, wQ, wK), 6 black pieces (bP, bN, bB, bR, bQ, bK), and empty squares (xx). Designed for board state recognition and FEN generation.

**Training:** ~93,000 synthetic images with aggressive augmentation (arrow overlays, flips, rotation, color jitter)

**Performance:** 99.84% accuracy on test data, 97.25% F1-score on real board images

### Arrows Model (`arrows.safetensors`)

Classifies chess square images into **49 classes** representing arrow overlay patterns: 20 arrow heads, 12 tails, 8 middle segments, 4 corners, and empty squares. Enables detection and reconstruction of arrow annotations in chess interfaces.

**Training:** ~93,000 synthetic images with conservative augmentation (no flips/rotation to preserve directionality)

**Performance:** ~99% accuracy on synthetic test data

Both models use the same SimpleCNN architecture (156k parameters) and are trained for 200 epochs using AdamW optimizer.

## üìö Documentation

For detailed documentation, visit [s1m0n38.github.io/chess-cv](https://s1m0n38.github.io/chess-cv/) or explore:

- **[Setup Guide](https://s1m0n38.github.io/chess-cv/setup/)** ‚Äì Installation and data preparation
- **[Train and Evaluate](https://s1m0n38.github.io/chess-cv/train-and-eval/)** ‚Äì Training, evaluation, and deployment
- **[Inference](https://s1m0n38.github.io/chess-cv/inference/)** ‚Äì Using pre-trained models and the library
- **[Architecture](https://s1m0n38.github.io/chess-cv/architecture/)** ‚Äì Model design and performance characteristics

## License

This project is licensed under the MIT License ‚Äì see the [LICENSE](LICENSE) file for details.

---

<div align="center">

[Get Started](#quick-start) ‚Ä¢ [Contribute](CONTRIBUTING.md) ‚Ä¢ [Report Issues](https://github.com/S1M0N38/chess-cv/issues)

</div>
